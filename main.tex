\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage[nolist,nohyperlinks]{acronym}
\usepackage[hidelinks]{hyperref}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\begin{acronym}
    \acro{MFCC}{Mel-frequency Cepstral Coefficients}
    \acro{DTW}{Dynamic Time Warping}
    \acro{STFT}{Short-Time Fourier Transform}
    \acro{ASR}{Automatic Speech Recognition}
    \acro{DCT}{Discrete Cosine Transform}
\end{acronym}

\title{Automatic Speech Recognition with \\ MFCC and DTW \\}
\author{\IEEEauthorblockN{João Borges}
\IEEEauthorblockA{\textit{Telecommunications, Automation and Electronics}\\ 
\textit{Research and Development Center (LASSE)}\\
\textit{Federal University of Pará}\\
Belém, Brazil \\
joao.tavares.borges@itec.ufpa.br}
}

\maketitle

\begin{abstract}
In this work, the Mel-frequency Cepstral Coefficient (MFCC) and 
Dynamic Time Warping (DTW) algorithms are implemented in 
Python to develop an isolated word recognition pipeline.
The system currently shows around 60\% accuracy in word identification.
\end{abstract}

\begin{IEEEkeywords}
MFCC, DTW, Speech Recognition 
\end{IEEEkeywords}

\section{Introduction}
The use of \ac{MFCC}\cite{dash2012speaker} to extract audio feature 
and \ac{DTW}\cite{sakoe1978dynamic} to compare the obtained values is 
a classical method of \ac{ASR} for simple isolated word 
detection \cite{muda2010voice}. This method leverages the Mel frequency 
scale, that is designed to be a perceptually relevant scale for pitch, 
meaning that equal frequency distances have the same perceptual 
difference from a human listener point of view. 

\section{Data Processing Pipeline}
This work uses a dataset composed of 105,000 WAVE audio files, with 30 different 
classes, obtained from Tensorflow\footnote{https://storage.cloud.google.com/download.tensorflow.org/data/\\
speech\_commands\_v0.02.tar.gz}, from which a subset of 5 classes, with 25 samples each, 
will be used in the experiments. The dataset is divided into 80\% for training 
and 20\% for validation. The remaining process can be split into 4 steps:

\begin{itemize}
    \item Calculate \ac{MFCC} for all signals
    \item Perform \ac{DTW} between sample and reference signals to find the most similar ones
    \item Check if the most similar sample have the same label as the reference (i.e. both are "cat"). 
    If yes, then increment the recognition score. 
    \item After finishing the process, obtain the mean between successful recognitions versus 
    number of samples, which is the recognition rate.
\end{itemize}

In the following subsections each of these steps will be described in details.

\subsection{Obtaining the MFCCs}
 The \acp{MFCC} of all audio files are calculated with the following steps:
% \begin{itemize}
% \item The signal goes through a pre-emphasis filter
% \item After that, it gets sliced into overlapping frames
% \item A window function is applied to the frames
% \item A \ac{STFT} is executed and the power spectrums are calculated 
% \item The filter banks are computed
% \item The MFCC is obtained by applying \ac{DCT} to the filter banks
% \item Normalization step
% \end{itemize}

\begin{itemize}
    \item The signal goes through a process of \ac{STFT}
    \item After that, the Mel filter banks are calculated
    \item Then, a dot product between the previous results, 
    followed by a dB conversion, are performed to obtain the 
    melspectrogram
    \item Finally, the \ac{MFCC} is obtained by applying \ac{DCT} to the 
    melspectrogram
\end{itemize}

\subsubsection{Short-Time Fourier Transform Step}

Due to the highly non stationary nature of speech data, composed of different 
phonemes with their own frequencies distributed along the time, it is necessary
to visualize how the signal spectrum changes over time, a feature 
absent in the traditional Fourier transform technique. This motivates the method 
known as \ac{STFT}, that divides the signal into frames through a process of 
windowing and then applies the Fourier transform in each one of them. These 
frames usually need to be overlapped in order to avoid loss of signal.
In the current implementation, the \ac{STFT} adopts the widely used 
\textit{Hann} window for the windowing process, as it smooths the discontinuities, 
avoiding the artifacts over the spectrum seen when rectangular windows are used.

\subsubsection{Mel filter banks}
To calculate the Mel filter banks, first is necessary to determine the number of 
Mel bands that will be used, then obtain the lowest and highest frequencies of 
the signal in the Mel scale. After that the interval between the lowest and the 
highest frequencies must be divided into a number of evenly separated points, equal 
to the number of Mel bands. These points are then converted back to the Hertz 
scale and rounded to the nearest bin. Finally, the triangular filters are created.

\subsubsection{The melspectrogram and the MFCC}
In order to obtain the melspectrogram first we need the spectrogram, which is obtained
by squaring the magnitude of the \ac{STFT} result. After that, a dot product is executed 
between the spectrogram and the Mel filter banks, followed by a power to dB conversion, 
resulting in the melspectrogram. To obtain the \ac{MFCC}, this spectrogram goes through
a \ac{DCT}. This last transformation could be a Fourier transform, but in order to discard
the complex valued component, the \ac{DCT} is used instead.
 
\subsection{Performing the DTW and Evaluating the System Performance}
After obtaining the \acp{MFCC} of all the dataset, 20\% of it is separated to act as 
validation set. The next step is to evaluate if the system can successfully compare the 
\acp{MFCC} of the sample and validation sets to point out similar words. This similarity
is calculated using \ac{DTW}, which is a method used to compare two sequences of numbers with 
different lengths \cite{sakoe1978dynamic}. The implementation utilized for the \ac{DTW} 
is publicly available in an online repository\footnote{https://github.com/pierre-rouanet/dtw}.

The procedure to obtain the recognition rate is the following:

\begin{itemize}
    \item First, a sample from the validation set is chosen
    \item After that, the system performs \ac{DTW} between this sample
and all the others in the training set, to get the one that has the 
\ac{MFCC} with the highest degree of similarity, in other words, the one that has the minimum
distance calculated via \ac{DTW}
    \item The system then checks if this sample, with minimum distance from the reference, 
    corresponds to the same word. If yes, then the system correctly recognized the word by 
    checking \ac{MFCC} similarity with \ac{DTW}, increasing one point in the recognition score
    \item Finally, after performing the same process for all samples in the validation set, the system
    calculates a mean score by dividing it with the amount of samples in the validation set. 
\end{itemize}

\section{Conclusion}
The \ac{ASR} performed by the described pipeline resulted in a 60\% accuracy rate for the subset utilized
in the experiments. This performance can be improved by tuning several hyperparameters from the processes
described, such as the number of FFT points and window overlap and stride in the \ac{STFT}, or the number
of Mel bands in the Mel filter bank design etc. The code used is available 
publicly in an online repository\footnote{https://github.com/joaotavares43/asr-jupyter/blob/main/asr.ipynb}

% \begin{figure}[htbp]
% %\centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}


% \section*{References}

% Please number citations consecutively within brackets \cite{IEEEhowto:IEEEtranpage}. The 
% sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
% number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
% the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

% Number footnotes separately in superscripts. Place the actual footnote at 
% the bottom of the column in which it was cited. Do not put footnotes in the 
% abstract or reference list. Use letters for table footnotes.

% Unless there are six authors or more give all authors' names; do not use 
% ``et al.''. Papers that have not been published, even if they have been 
% submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
% that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
% Capitalize only the first word in a paper title, except for proper nouns and 
% element symbols.

% For papers published in translation journals, please give the English 
% citation first, followed by the original foreign-language citation \cite{b6}.

\bibliographystyle{./bibliography/IEEEtran}
\bibliography{./bibliography/IEEEabrv,./bibliography/IEEEexample}

% \vspace{12pt}
% \color{red}
% IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
